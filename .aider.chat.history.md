
# aider chat started at 2025-02-24 12:17:34

> Models which match "gemini/":  
> - gemini/gemini-1.5-flash  
> - gemini/gemini-1.5-flash-001  
> - gemini/gemini-1.5-flash-002  
> - gemini/gemini-1.5-flash-8b  
> - gemini/gemini-1.5-flash-8b-exp-0827  
> - gemini/gemini-1.5-flash-8b-exp-0924  
> - gemini/gemini-1.5-flash-exp-0827  
> - gemini/gemini-1.5-flash-latest  
> - gemini/gemini-1.5-pro  
> - gemini/gemini-1.5-pro-001  
> - gemini/gemini-1.5-pro-002  
> - gemini/gemini-1.5-pro-exp-0801  
> - gemini/gemini-1.5-pro-exp-0827  
> - gemini/gemini-1.5-pro-latest  
> - gemini/gemini-2.0-flash  
> - gemini/gemini-2.0-flash-001  
> - gemini/gemini-2.0-flash-exp  
> - gemini/gemini-2.0-flash-lite-preview-02-05  
> - gemini/gemini-2.0-flash-thinking-exp  
> - gemini/gemini-exp-1114  
> - gemini/gemini-exp-1206  
> - gemini/gemini-gemma-2-27b-it  
> - gemini/gemini-gemma-2-9b-it  
> - gemini/gemini-pro  
> - gemini/gemini-pro-vision  

# aider chat started at 2025-02-24 12:19:32

> You can skip this check with --no-gitignore  
> Add .aider* to .gitignore (recommended)? (Y)es/(N)o [Yes]: y  
> Added .aider* to .gitignore  
> C:\Users\Maxim\AppData\Local\Programs\Python\Python311\Scripts\aider --model gemini/gemini-1.5-pro-latest  
> Warning: gemini/gemini-1.5-pro-latest expects these environment variables  
> - GEMINI_API_KEY: Not set  
> Note: You may need to restart your terminal or command prompt for `setx` to take effect.  
> You can skip this check with --no-show-model-warnings  
> https://aider.chat/docs/llms/warnings.html  
> Open documentation url for more info? (Y)es/(N)o/(D)on't ask again [Yes]: n  
> Aider v0.74.3  
> Model: gemini/gemini-1.5-pro-latest with diff-fenced edit format  
> Git repo: .git with 559 files  
> Repo-map: using 4096 tokens, auto refresh  
> https://aider.chat/HISTORY.html#release-notes  
> Would you like to see what's new in this version? (Y)es/(N)o [Yes]: n  

#### test  
> Initial repo scan can be slow in larger repos, but only happens once.  
> litellm.AuthenticationError: vertex_ai_betaException - b'{\n  "error": {\n    "code": 400,\n    "message": "API key not valid. Please pass a valid API key.",\n    "status": "INVALID_ARGUMENT",\n    "details": [\n      {\n        "@type": "type.googleapis.com/google.rpc.ErrorInfo",\n        "reason": "API_KEY_INVALID",\n        "domain": "googleapis.com",\n        "metadata": {\n          "service": "generativelanguage.googleapis.com"\n        }\n      },\n      {\n        "@type": "type.googleapis.com/google.rpc.LocalizedMessage",\n        "locale": "en-US",\n        "message": "API key not valid. Please pass a valid API key."\n      }\n    ]\n  }\n}\n'  
> The API provider is not able to authenticate you. Check your API key.  
>  
>  
> ^C again to exit  
>  
>  
> ^C KeyboardInterrupt  

# aider chat started at 2025-02-24 12:20:58

> C:\Users\Maxim\AppData\Local\Programs\Python\Python311\Scripts\aider test  
> You need to specify a --model and an --api-key to use.  
> https://aider.chat/docs/troubleshooting/models-and-keys.html  
> Open documentation url for more info? (Y)es/(N)o/(D)on't ask again [Yes]: y  

# aider chat started at 2025-02-24 18:54:21

> C:\Users\Maxim\AppData\Local\Programs\Python\Python311\Scripts\aider  
> Found GEMINI_API_KEY so using flash since no --model was specified.  
> Aider v0.74.3  
> Model: gemini/gemini-2.0-flash-exp with diff edit format  
> Git repo: .git with 559 files  
> Repo-map: using 4096 tokens, auto refresh  

#### /ask what time is it  

#### what time is it  

I do not have access to real-time information, including the current time.

> Tokens: 6.9k sent, 15 received.  

#### /ask explain the repo  

#### explain the repo  

Okay, from the file list you've provided, it appears this repository is designed for document processing, classification, and information extraction, potentially for a school board or similar organization. Here's a breakdown of the likely purpose of each section:

*   **`data/`**: This directory seems to be the central data storage area.
    *   `data/documents/`: Likely holds the core documents, organized by classification status (e.g., `Classified`, `In_Processing`, `raw_documents`). The subdirectories within `Classified` suggest further categorization based on document type (PDF with images, PDF with text, text-only, etc.).
    *   `data/classification_combinations.json`: Probably stores information about the combinations of classifications that have been applied to documents.
    *   `data/raw_documents/`: Contains the original, unprocessed documents.
*   **`experiments/`**: This directory is for experimental code and data, likely related to improving the document processing pipeline. The `1_prelearning` and `2_modularization_Ollama` subdirectories suggest different experimental approaches.
    *   `experiments/1_prelearning/`: Seems to be focused on pre-training or initial learning phases for a model.
        *   `data/converted_documents/`: Contains text files converted from the original documents, likely for use in training a model.
        *   `data/documents_chunks/`: Contains smaller chunks of text from the documents, possibly for processing by a language model due to token limits.
        *   `data/entities/`: Stores extracted entities from the documents.
        *   `data/logs/`: Contains logs of various processes, such as benchmarking, entity extraction, and indexing.
        *   `data/processed_text/`: Contains text files that have been preprocessed (e.g., cleaned, normalized).
        *   `data/prompts/`: Contains prompt templates used for interacting with a language model.
        *   `src/`: Contains Python scripts for the different steps in the pre-learning process (reading documents, preprocessing, extracting entities, extracting relationships).
    *   `experiments/2_modularization_Ollama/`: Appears to be an experiment in modularizing the document processing pipeline, potentially using the Ollama language model.
        *   `inbound_documents/`: Input documents for the modularized pipeline.
        *   `outbound_documents/`: Output documents from the modularized pipeline.
        *   `prompts/`: Prompt templates for the Ollama model.
        *   `src/`: Python scripts for the modularized pipeline, including scripts for calling Ollama, indexing, and converting data formats.
*   **`src/`**: This directory contains the source code for the main document processing pipeline.
    *   `src/2 - Document Classifier/`: Contains scripts for classifying documents.
    *   `src/_bckp_1 - Document Storage ELT/`: This seems to be a backup or earlier version of the document storage, extraction, loading, and transformation (ELT) pipeline. It includes scripts for indexing documents, classifying documents, managing files, and setting up logging.
    *   `src/classifiers/`: Contains classifier modules, specifically for PDF documents.
*   **Other files:**
    *   `library_strategy_graphs.py`: Might contain code for extracting data from documents and creating library strategy graphs.
    *   `experiments/_side_using_LLM_to_analyze_tables/Table Analyzer using LLM.md`: Indicates an experiment using a language model to analyze tables.
    *   `src/Document Pre-Processing.md`: A markdown file describing document pre-processing steps.
    *   `src/readme.md`: A general readme file for the repository.

In summary, this repository implements a document processing pipeline that includes:

1.  **Document Indexing:** Creating an index of documents and their metadata.
2.  **Document Classification:** Categorizing documents based on their content and type.
3.  **Information Extraction:** Extracting entities and relationships from the documents using language models.
4.  **Storage and Management:** Organizing and storing documents in a structured manner.
5.  **Experimentation:** Exploring different approaches to improve the pipeline, such as using different language models or modularizing the code.

The repository appears to be actively developed, with ongoing experiments and a focus on using language models for information extraction and analysis. The presence of backup directories suggests a careful approach to development and version control.

> Tokens: 6.9k sent, 920 received.  
> library_strategy_graphs.py  
> Add file to the chat? (Y)es/(N)o/(A)ll/(S)kip all/(D)on't ask again [Yes]: n  
> src\readme.md  
> Add file to the chat? (Y)es/(N)o/(A)ll/(S)kip all/(D)on't ask again [Yes]: n  

#### /tokens  
> Approximate context window usage for gemini/gemini-2.0-flash-exp, in tokens:  
> $ 0.0000    1,949 system messages  
> $ 0.0000      961 chat history    use /clear to clear  
> $ 0.0000    6,817 repository map  use --map-tokens to resize  
> ==================  
> $ 0.0000    9,727 tokens total  
> 1,038,849 tokens remaining in context window  
> 1,048,576 tokens max context window size  

#### /copy-context  
> Copied code context to clipboard.  
>  
>  
> ^C again to exit  

#### /code help me create a yaml config file  

#### help me create a yaml config file  

Okay, I can help you create a YAML configuration file. To do this effectively, I need to know what aspects of your document processing pipeline you want to configure.

Please tell me:

1.  **What settings do you want to control with this config file?** For example:
    *   Input/output directories
    *   File extensions to process
    *   Language model settings (model name, API endpoint, etc.)
    *   Chunking parameters (chunk size, overlap)
    *   Logging levels
    *   Decision tree file path
    *   Thresholds or parameters for any of the processing steps
2.  **Where will this config file be located?** (e.g., root directory, `config/` directory, etc.)

Once I have this information, I can create the YAML file content and provide you with a *SEARCH/REPLACE* block to create the file.

> Tokens: 10k sent, 185 received.  

#### what is my google api key  

I am an AI and do not have access to your personal information, including your Google API key. I cannot retrieve it for you. API keys are sensitive and should be stored securely and not shared.

If you need to find your Google API key, you should:

1.  Go to the Google Cloud Console: `https://console.cloud.google.com/`
2.  Select the project you are using.
3.  Navigate to "APIs & Services" > "Credentials".
4.  Look for your API key in the list.

If you still can't find it, consult the Google Cloud documentation for more help.

> Tokens: 10k sent, 126 received.  

#### /chat-mode  
> Chat mode should be one of these:  
> - help         : Get help about using aider (usage, config, troubleshoot).  
> - ask          : Ask questions about your code without making any changes.  
> - code         : Ask for changes to your code (using the best edit format).  
> - architect    : Work with an architect model to design code changes, and an editor to make them.  
> Or a valid edit format:  
> - diff         : A coder that uses search/replace blocks for code modifications.  
> - diff-fenced  : A coder that uses fenced search/replace blocks for code modifications.  
> - editor-diff  : A coder that uses search/replace blocks, focused purely on editing files.  
> - editor-whole : A coder that operates on entire files, focused purely on editing files.  
> - udiff        : A coder that uses unified diff format for code modifications.  
> - whole        : A coder that operates on entire files for code modifications.  

#### help  

How can I help you? Do you want me to create that YAML config file? If so, please provide the information I requested earlier about the settings you want to control.

> Tokens: 11k sent, 35 received.  

#### /code start populating the config yaml file - google api - AIzaSyCS7_C8G2Q-pO7fKH6MVfIskIG-V0113Yw  

#### start populating the config yaml file - google api - AIzaSyCS7_C8G2Q-pO7fKH6MVfIskIG-V0113Yw  

Okay, I will create a `config.yaml` file with the Google API key you provided.

config.yaml
```yaml
<<<<<<< SEARCH
=======
google_api_key: AIzaSyCS7_C8G2Q-pO7fKH6MVfIskIG-V0113Yw
>>>>>>> REPLACE
```

After you apply this change, you might want to add more configuration parameters to the file.
```bash
mkdir config
mv config.yaml config/config.yaml
```

> Tokens: 11k sent, 98 received.  
> configs\config.yaml  
> Add file to the chat? (Y)es/(N)o/(D)on't ask again [Yes]: d  
> config.yaml  
> Create new file? (Y)es/(N)o [Yes]: y  
> Applied edit to config.yaml  
> Commit c09c202 feat: Add initial config.yaml with google_api_key.  
> mkdir config                     
mv config.yaml config/config.yaml  
> Run shell commands? (Y)es/(N)o/(D)on't ask again [Yes]: d  

#### /ask where did you place this file?  

#### where did you place this file?  

Based on our previous conversation, I suggested creating a `config` directory and placing the `config.yaml` file inside it. So, the intended location was:

```
config/config.yaml
```

However, I don't *actually* place the file anywhere. I just provide you with the content and instructions on where to put it in your repository. You are the one who creates the file and puts it in the correct location.

Is it located in `config/config.yaml` in your repository?

> Tokens: 6.2k sent, 100 received.  

#### /ask find the file and echo here along with the path  

#### find the file and echo here along with the path  

I am unable to directly access your file system. I can only work with the file contents that you provide to me in the chat. I cannot "find" files on your computer.

You would need to use a command in your terminal to find the file. For example, in a Linux or macOS environment, you could use the `find` command:

```bash
find . -name "config.yaml"
```

This command will search the current directory (`.`) and all its subdirectories for a file named "config.yaml" and print its path.

> Tokens: 6.4k sent, 112 received.  

####  find . -name "config.yaml"  

I understand the rules for *SEARCH/REPLACE* blocks. However, your request is to "find the file and echo here along with the path". I cannot perform file system operations. I can only provide *SEARCH/REPLACE* blocks for files that you have added to the chat.

If you run the `find . -name "config.yaml"` command in your terminal, it will print the path to the file. You can then tell me the path, and I can use that path in future *SEARCH/REPLACE* blocks.

> Tokens: 8.7k sent, 110 received.  
>  
>  
> ^C again to exit  

#### cd /c:/Users/Maxim/Documents/VSCode/school_board_library  
#### git rm configs/config.yaml  
#### git commit -m "Remove configs/config.yaml from repository"  
#### git push  
> litellm.BadRequestError: VertexAIException BadRequestError - b'{\n  "error": {\n    "code": 400,\n    "message": "API key expired. Please renew the API key.",\n    "status": "INVALID_ARGUMENT",\n    "details": [\n      {\n        "@type": "type.googleapis.com/google.rpc.ErrorInfo",\n        "reason": "API_KEY_INVALID",\n        "domain": "googleapis.com",\n        "metadata": {\n          "service": "generativelanguage.googleapis.com"\n        }\n      },\n      {\n        "@type": "type.googleapis.com/google.rpc.LocalizedMessage",\n        "locale": "en-US",\n        "message": "API key expired. Please renew the API key."\n      }\n    ]\n  }\n}\n'  

# aider chat started at 2025-02-24 19:35:50

> C:\Users\Maxim\AppData\Local\Programs\Python\Python311\Scripts\aider  
> Found GEMINI_API_KEY so using flash since no --model was specified.  
> Aider v0.74.3  
> Model: gemini/gemini-2.0-flash-exp with diff edit format  
> Git repo: .git with 567 files  
> Repo-map: using 4096 tokens, auto refresh  

#### /clear  

#### --version  
> litellm.BadRequestError: VertexAIException BadRequestError - b'{\n  "error": {\n    "code": 400,\n    "message": "API key expired. Please renew the API key.",\n    "status": "INVALID_ARGUMENT",\n    "details": [\n      {\n        "@type": "type.googleapis.com/google.rpc.ErrorInfo",\n        "reason": "API_KEY_INVALID",\n        "domain": "googleapis.com",\n        "metadata": {\n          "service": "generativelanguage.googleapis.com"\n        }\n      },\n      {\n        "@type": "type.googleapis.com/google.rpc.LocalizedMessage",\n        "locale": "en-US",\n        "message": "API key expired. Please renew the API key."\n      }\n    ]\n  }\n}\n'  

#### --version  
> litellm.BadRequestError: VertexAIException BadRequestError - b'{\n  "error": {\n    "code": 400,\n    "message": "API key expired. Please renew the API key.",\n    "status": "INVALID_ARGUMENT",\n    "details": [\n      {\n        "@type": "type.googleapis.com/google.rpc.ErrorInfo",\n        "reason": "API_KEY_INVALID",\n        "domain": "googleapis.com",\n        "metadata": {\n          "service": "generativelanguage.googleapis.com"\n        }\n      },\n      {\n        "@type": "type.googleapis.com/google.rpc.LocalizedMessage",\n        "locale": "en-US",\n        "message": "API key expired. Please renew the API key."\n      }\n    ]\n  }\n}\n'  

#### model  
> litellm.BadRequestError: VertexAIException BadRequestError - b'{\n  "error": {\n    "code": 400,\n    "message": "API key expired. Please renew the API key.",\n    "status": "INVALID_ARGUMENT",\n    "details": [\n      {\n        "@type": "type.googleapis.com/google.rpc.ErrorInfo",\n        "reason": "API_KEY_INVALID",\n        "domain": "googleapis.com",\n        "metadata": {\n          "service": "generativelanguage.googleapis.com"\n        }\n      },\n      {\n        "@type": "type.googleapis.com/google.rpc.LocalizedMessage",\n        "locale": "en-US",\n        "message": "API key expired. Please renew the API key."\n      }\n    ]\n  }\n}\n'  

#### /exit  

# aider chat started at 2025-02-24 21:04:28

> You can skip this check with --no-gitignore  
> Add .aider* to .gitignore (recommended)? (Y)es/(N)o [Yes]: y  
> Added .aider* to .gitignore  
> C:\Users\Maxim\AppData\Local\Programs\Python\Python311\Scripts\aider  
> Warning: gpt-4-turbo-preview expects these environment variables  
> - OPENAI_API_KEY: Not set  
> Note: You may need to restart your terminal or command prompt for `setx` to take effect.  
> You can skip this check with --no-show-model-warnings  
> https://aider.chat/docs/llms/warnings.html  
> Open documentation url for more info? (Y)es/(N)o/(D)on't ask again [Yes]: n  
> Aider v0.74.3  
> Model: gpt-4-turbo-preview with udiff edit format  
> Git repo: ..\.git with 573 files  
> Repo-map: using 4096 tokens, auto refresh  
> Note: in-chat filenames are always relative to the git working dir, not the current working dir.  
> Cur working dir: C:\Users\Maxim\Documents\VSCode\school_board_library\aider  
> Git working dir: C:\Users\Maxim\Documents\VSCode\school_board_library  

#### /model  
> Warning for : Unknown context window size and costs, using sane defaults.  
> Did you mean one of these?  
> - accounts/fireworks/models/llama-v3p2-90b-vision-instruct  
> - ai21.j2-mid-v1  
> - ai21.j2-ultra-v1  
> - ai21.jamba-1-5-large-v1:0  
> - ai21.jamba-1-5-mini-v1:0  
> - ai21.jamba-instruct-v1:0  
> - ai21/jamba-1.5  
> - ai21/jamba-1.5-large  
> - ai21/jamba-1.5-large@001  
> - ai21/jamba-1.5-mini  
> - ai21/jamba-1.5-mini@001  
> - aleph_alpha/luminous-base-control  
> - aleph_alpha/luminous-extended-control  
> - aleph_alpha/luminous-supreme-control  
> - amazon.nova-lite-v1:0  
> - amazon.nova-micro-v1:0  
> - amazon.nova-pro-v1:0  
> - amazon.titan-text-express-v1  
> - amazon.titan-text-lite-v1  
> - amazon.titan-text-premier-v1:0  
> - anthropic.claude-3-5-haiku-20241022-v1:0  
> - anthropic.claude-3-5-sonnet-20240620-v1:0  
> - anthropic.claude-3-5-sonnet-20241022-v2:0  
> - anthropic.claude-3-7-sonnet-20250219-v1:0  
> - anthropic.claude-3-haiku-20240307-v1:0  
> - anthropic.claude-3-opus-20240229-v1:0  
> - anthropic.claude-3-sonnet-20240229-v1:0  
> - anthropic.claude-instant-v1  
> - anthropic.claude-v1  
> - anthropic.claude-v2  
> - anthropic.claude-v2:1  
> - anthropic/claude-2  
> - anthropic/claude-2.1  
> - anthropic/claude-3-5-haiku-20241022  
> - anthropic/claude-3-5-sonnet-20240620  
> - anthropic/claude-3-5-sonnet-20241022  
> - anthropic/claude-3-7-sonnet-20250219  
> - anthropic/claude-3-haiku-20240307  
> - anthropic/claude-3-opus-20240229  
> - anthropic/claude-3-sonnet-20240229  
> - anthropic/claude-instant-1  
> - anthropic/claude-instant-1.2  
> - anyscale/HuggingFaceH4/zephyr-7b-beta  
> - anyscale/codellama/CodeLlama-34b-Instruct-hf  
> - anyscale/codellama/CodeLlama-70b-Instruct-hf  
> - anyscale/google/gemma-7b-it  
> - anyscale/meta-llama/Llama-2-13b-chat-hf  
> - anyscale/meta-llama/Llama-2-70b-chat-hf  
> - anyscale/meta-llama/Llama-2-7b-chat-hf  
> - anyscale/meta-llama/Meta-Llama-3-70B-Instruct  
> - anyscale/meta-llama/Meta-Llama-3-8B-Instruct  
> - anyscale/mistralai/Mistral-7B-Instruct-v0.1  
> - anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1  
> - anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1  
> - azure/command-r-plus  
> - azure/global-standard/gpt-4o-2024-08-06  
> - azure/global-standard/gpt-4o-2024-11-20  
> - azure/global-standard/gpt-4o-mini  
> - azure/gpt-3.5-turbo  
> - azure/gpt-3.5-turbo-0125  
> - azure/gpt-35-turbo  
> - azure/gpt-35-turbo-0125  
> - azure/gpt-35-turbo-0301  
> - azure/gpt-35-turbo-0613  
> - azure/gpt-35-turbo-1106  
> - azure/gpt-35-turbo-16k  
> - azure/gpt-35-turbo-16k-0613  
> - azure/gpt-4  
> - azure/gpt-4-0125-preview  
> - azure/gpt-4-0613  
> - azure/gpt-4-1106-preview  
> - azure/gpt-4-32k  
> - azure/gpt-4-32k-0613  
> - azure/gpt-4-turbo  
> - azure/gpt-4-turbo-2024-04-09  
> - azure/gpt-4-turbo-vision-preview  
> - azure/gpt-4o  
> - azure/gpt-4o-2024-05-13  
> - azure/gpt-4o-2024-08-06  
> - azure/gpt-4o-2024-11-20  
> - azure/gpt-4o-mini  
> - azure/gpt-4o-mini-2024-07-18  
> - azure/mistral-large-2402  
> - azure/mistral-large-latest  
> - azure/o1  
> - azure/o1-2024-12-17  
> - azure/o1-mini  
> - azure/o1-mini-2024-09-12  
> - azure/o1-preview  
> - azure/o1-preview-2024-09-12  
> - azure/o3-mini  
> - azure/o3-mini-2025-01-31  
> - azure_ai/Llama-3.2-11B-Vision-Instruct  
> - azure_ai/Llama-3.2-90B-Vision-Instruct  
> - azure_ai/Llama-3.3-70B-Instruct  
> - azure_ai/Meta-Llama-3-70B-Instruct  
> - azure_ai/Meta-Llama-3.1-405B-Instruct  
> - azure_ai/Meta-Llama-3.1-70B-Instruct  
> - azure_ai/Meta-Llama-3.1-8B-Instruct  
> - azure_ai/Phi-3-medium-128k-instruct  
> - azure_ai/Phi-3-medium-4k-instruct  
> - azure_ai/Phi-3-mini-128k-instruct  
> - azure_ai/Phi-3-mini-4k-instruct  
> - azure_ai/Phi-3-small-128k-instruct  
> - azure_ai/Phi-3-small-8k-instruct  
> - azure_ai/Phi-3.5-MoE-instruct  
> - azure_ai/Phi-3.5-mini-instruct  
> - azure_ai/Phi-3.5-vision-instruct  
> - azure_ai/deepseek-r1  
> - azure_ai/jamba-instruct  
> - azure_ai/ministral-3b  
> - azure_ai/mistral-large  
> - azure_ai/mistral-large-2407  
> - azure_ai/mistral-small  
> - bedrock/*/1-month-commitment/cohere.command-light-text-v14  
> - bedrock/*/1-month-commitment/cohere.command-text-v14  
> - bedrock/*/6-month-commitment/cohere.command-light-text-v14  
> - bedrock/*/6-month-commitment/cohere.command-text-v14  
> - bedrock/ai21.j2-mid-v1  
> - bedrock/ai21.j2-ultra-v1  
> - bedrock/ai21.jamba-1-5-large-v1:0  
> - bedrock/ai21.jamba-1-5-mini-v1:0  
> - bedrock/ai21.jamba-instruct-v1:0  
> - bedrock/amazon.titan-text-express-v1  
> - bedrock/amazon.titan-text-lite-v1  
> - bedrock/amazon.titan-text-premier-v1:0  
> - bedrock/anthropic.claude-3-5-haiku-20241022-v1:0  
> - bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0  
> - bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0  
> - bedrock/anthropic.claude-3-haiku-20240307-v1:0  
> - bedrock/anthropic.claude-3-opus-20240229-v1:0  
> - bedrock/anthropic.claude-3-sonnet-20240229-v1:0  
> - bedrock/anthropic.claude-instant-v1  
> - bedrock/anthropic.claude-v1  
> - bedrock/anthropic.claude-v2  
> - bedrock/anthropic.claude-v2:1  
> - bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1  
> - bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1  
> - bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2  
> - bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1  
> - bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1  
> - bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1  
> - bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2  
> - bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1  
> - bedrock/ap-northeast-1/anthropic.claude-instant-v1  
> - bedrock/ap-northeast-1/anthropic.claude-v1  
> - bedrock/ap-northeast-1/anthropic.claude-v2  
> - bedrock/ap-northeast-1/anthropic.claude-v2:1  
> - bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/cohere.command-light-text-v14  
> - bedrock/cohere.command-r-plus-v1:0  
> - bedrock/cohere.command-r-v1:0  
> - bedrock/cohere.command-text-v14  
> - bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1  
> - bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1  
> - bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2  
> - bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1  
> - bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1  
> - bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1  
> - bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2  
> - bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1  
> - bedrock/eu-central-1/anthropic.claude-instant-v1  
> - bedrock/eu-central-1/anthropic.claude-v1  
> - bedrock/eu-central-1/anthropic.claude-v2  
> - bedrock/eu-central-1/anthropic.claude-v2:1  
> - bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0  
> - bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0  
> - bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2  
> - bedrock/eu-west-3/mistral.mistral-large-2402-v1:0  
> - bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1  
> - bedrock/eu.anthropic.claude-3-5-haiku-20241022-v1:0  
> - bedrock/eu.anthropic.claude-3-5-sonnet-20240620-v1:0  
> - bedrock/eu.anthropic.claude-3-5-sonnet-20241022-v2:0  
> - bedrock/eu.anthropic.claude-3-haiku-20240307-v1:0  
> - bedrock/eu.anthropic.claude-3-opus-20240229-v1:0  
> - bedrock/eu.anthropic.claude-3-sonnet-20240229-v1:0  
> - bedrock/eu.meta.llama3-2-1b-instruct-v1:0  
> - bedrock/eu.meta.llama3-2-3b-instruct-v1:0  
> - bedrock/meta.llama2-13b-chat-v1  
> - bedrock/meta.llama2-70b-chat-v1  
> - bedrock/meta.llama3-1-405b-instruct-v1:0  
> - bedrock/meta.llama3-1-70b-instruct-v1:0  
> - bedrock/meta.llama3-1-8b-instruct-v1:0  
> - bedrock/meta.llama3-2-11b-instruct-v1:0  
> - bedrock/meta.llama3-2-1b-instruct-v1:0  
> - bedrock/meta.llama3-2-3b-instruct-v1:0  
> - bedrock/meta.llama3-2-90b-instruct-v1:0  
> - bedrock/meta.llama3-70b-instruct-v1:0  
> - bedrock/meta.llama3-8b-instruct-v1:0  
> - bedrock/mistral.mistral-7b-instruct-v0:2  
> - bedrock/mistral.mistral-large-2402-v1:0  
> - bedrock/mistral.mistral-large-2407-v1:0  
> - bedrock/mistral.mistral-small-2402-v1:0  
> - bedrock/mistral.mixtral-8x7b-instruct-v0:1  
> - bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1  
> - bedrock/us-east-1/1-month-commitment/anthropic.claude-v1  
> - bedrock/us-east-1/1-month-commitment/anthropic.claude-v2  
> - bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1  
> - bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1  
> - bedrock/us-east-1/6-month-commitment/anthropic.claude-v1  
> - bedrock/us-east-1/6-month-commitment/anthropic.claude-v2  
> - bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1  
> - bedrock/us-east-1/anthropic.claude-instant-v1  
> - bedrock/us-east-1/anthropic.claude-v1  
> - bedrock/us-east-1/anthropic.claude-v2  
> - bedrock/us-east-1/anthropic.claude-v2:1  
> - bedrock/us-east-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/us-east-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2  
> - bedrock/us-east-1/mistral.mistral-large-2402-v1:0  
> - bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1  
> - bedrock/us-west-1/meta.llama3-70b-instruct-v1:0  
> - bedrock/us-west-1/meta.llama3-8b-instruct-v1:0  
> - bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1  
> - bedrock/us-west-2/1-month-commitment/anthropic.claude-v1  
> - bedrock/us-west-2/1-month-commitment/anthropic.claude-v2  
> - bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1  
> - bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1  
> - bedrock/us-west-2/6-month-commitment/anthropic.claude-v1  
> - bedrock/us-west-2/6-month-commitment/anthropic.claude-v2  
> - bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1  
> - bedrock/us-west-2/anthropic.claude-instant-v1  
> - bedrock/us-west-2/anthropic.claude-v1  
> - bedrock/us-west-2/anthropic.claude-v2  
> - bedrock/us-west-2/anthropic.claude-v2:1  
> - bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2  
> - bedrock/us-west-2/mistral.mistral-large-2402-v1:0  
> - bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1  
> - bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0  
> - bedrock/us.anthropic.claude-3-5-sonnet-20240620-v1:0  
> - bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0  
> - bedrock/us.anthropic.claude-3-haiku-20240307-v1:0  
> - bedrock/us.anthropic.claude-3-opus-20240229-v1:0  
> - bedrock/us.anthropic.claude-3-sonnet-20240229-v1:0  
> - bedrock/us.meta.llama3-1-405b-instruct-v1:0  
> - bedrock/us.meta.llama3-1-70b-instruct-v1:0  
> - bedrock/us.meta.llama3-1-8b-instruct-v1:0  
> - bedrock/us.meta.llama3-2-11b-instruct-v1:0  
> - bedrock/us.meta.llama3-2-1b-instruct-v1:0  
> - bedrock/us.meta.llama3-2-3b-instruct-v1:0  
> - bedrock/us.meta.llama3-2-90b-instruct-v1:0  
> - bedrock_converse/amazon.nova-lite-v1:0  
> - bedrock_converse/amazon.nova-micro-v1:0  
> - bedrock_converse/amazon.nova-pro-v1:0  
> - bedrock_converse/anthropic.claude-3-7-sonnet-20250219-v1:0  
> - bedrock_converse/meta.llama3-3-70b-instruct-v1:0  
> - bedrock_converse/us.amazon.nova-lite-v1:0  
> - bedrock_converse/us.amazon.nova-micro-v1:0  
> - bedrock_converse/us.amazon.nova-pro-v1:0  
> - bedrock_converse/us.meta.llama3-3-70b-instruct-v1:0  
> - cerebras/llama3.1-70b  
> - cerebras/llama3.1-8b  
> - cerebras/llama3.3-70b  
> - chat-bison  
> - chat-bison-32k  
> - chat-bison-32k@002  
> - chat-bison@001  
> - chat-bison@002  
> - chatdolphin  
> - chatgpt-4o-latest  
> - claude-2  
> - claude-2.1  
> - claude-3-5-haiku-20241022  
> - claude-3-5-sonnet-20240620  
> - claude-3-5-sonnet-20241022  
> - claude-3-7-sonnet-20250219  
> - claude-3-haiku-20240307  
> - claude-3-opus-20240229  
> - claude-3-sonnet-20240229  
> - claude-instant-1  
> - claude-instant-1.2  
> - cloudflare/@cf/meta/llama-2-7b-chat-fp16  
> - cloudflare/@cf/meta/llama-2-7b-chat-int8  
> - cloudflare/@cf/mistral/mistral-7b-instruct-v0.1  
> - cloudflare/@hf/thebloke/codellama-7b-instruct-awq  
> - code-bison  
> - codechat-bison  
> - codechat-bison-32k  
> - codechat-bison-32k@002  
> - codechat-bison@001  
> - codechat-bison@002  
> - codechat-bison@latest  
> - codestral/codestral-2405  
> - codestral/codestral-latest  
> - cohere.command-light-text-v14  
> - cohere.command-r-plus-v1:0  
> - cohere.command-r-v1:0  
> - cohere.command-text-v14  
> - cohere_chat/command-light  
> - cohere_chat/command-r  
> - cohere_chat/command-r-08-2024  
> - cohere_chat/command-r-plus  
> - cohere_chat/command-r-plus-08-2024  
> - cohere_chat/command-r7b-12-2024  
> - command-light  
> - command-r  
> - command-r-08-2024  
> - command-r-plus  
> - command-r-plus-08-2024  
> - command-r7b-12-2024  
> - databricks/databricks-dbrx-instruct  
> - databricks/databricks-llama-2-70b-chat  
> - databricks/databricks-meta-llama-3-1-405b-instruct  
> - databricks/databricks-meta-llama-3-1-70b-instruct  
> - databricks/databricks-meta-llama-3-70b-instruct  
> - databricks/databricks-mixtral-8x7b-instruct  
> - databricks/databricks-mpt-30b-instruct  
> - databricks/databricks-mpt-7b-instruct  
> - databricks/meta-llama-3.3-70b-instruct  
> - deepinfra/01-ai/Yi-34B-Chat  
> - deepinfra/Gryphe/MythoMax-L2-13b  
> - deepinfra/Phind/Phind-CodeLlama-34B-v2  
> - deepinfra/amazon/MistralLite  
> - deepinfra/codellama/CodeLlama-34b-Instruct-hf  
> - deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b  
> - deepinfra/deepinfra/airoboros-70b  
> - deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1  
> - deepinfra/lizpreciatior/lzlv_70b_fp16_hf  
> - deepinfra/meta-llama/Llama-2-13b-chat-hf  
> - deepinfra/meta-llama/Llama-2-70b-chat-hf  
> - deepinfra/meta-llama/Llama-2-7b-chat-hf  
> - deepinfra/meta-llama/Meta-Llama-3-70B-Instruct  
> - deepinfra/meta-llama/Meta-Llama-3-8B-Instruct  
> - deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct  
> - deepinfra/mistralai/Mistral-7B-Instruct-v0.1  
> - deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1  
> - deepinfra/openchat/openchat_3.5  
> - deepseek/deepseek-chat  
> - deepseek/deepseek-coder  
> - deepseek/deepseek-reasoner  
> - eu.anthropic.claude-3-5-haiku-20241022-v1:0  
> - eu.anthropic.claude-3-5-sonnet-20240620-v1:0  
> - eu.anthropic.claude-3-5-sonnet-20241022-v2:0  
> - eu.anthropic.claude-3-haiku-20240307-v1:0  
> - eu.anthropic.claude-3-opus-20240229-v1:0  
> - eu.anthropic.claude-3-sonnet-20240229-v1:0  
> - eu.meta.llama3-2-1b-instruct-v1:0  
> - eu.meta.llama3-2-3b-instruct-v1:0  
> - fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct  
> - fireworks_ai/accounts/fireworks/models/deepseek-v3  
> - fireworks_ai/accounts/fireworks/models/firefunction-v2  
> - fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct  
> - fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct  
> - fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct  
> - fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct  
> - fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct  
> - fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf  
> - fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct  
> - fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct  
> - fireworks_ai/accounts/fireworks/models/yi-large  
> - friendliai/meta-llama-3.1-70b-instruct  
> - friendliai/meta-llama-3.1-8b-instruct  
> - ft:gpt-3.5-turbo  
> - ft:gpt-3.5-turbo-0125  
> - ft:gpt-3.5-turbo-0613  
> - ft:gpt-3.5-turbo-1106  
> - ft:gpt-4-0613  
> - ft:gpt-4o-2024-08-06  
> - ft:gpt-4o-2024-11-20  
> - ft:gpt-4o-mini-2024-07-18  
> - gemini-1.0-pro  
> - gemini-1.0-pro-001  
> - gemini-1.0-pro-002  
> - gemini-1.0-pro-vision  
> - gemini-1.0-pro-vision-001  
> - gemini-1.0-ultra  
> - gemini-1.0-ultra-001  
> - gemini-1.5-flash  
> - gemini-1.5-flash-001  
> - gemini-1.5-flash-002  
> - gemini-1.5-flash-exp-0827  
> - gemini-1.5-flash-preview-0514  
> - gemini-1.5-pro  
> - gemini-1.5-pro-001  
> - gemini-1.5-pro-002  
> - gemini-1.5-pro-preview-0215  
> - gemini-1.5-pro-preview-0409  
> - gemini-1.5-pro-preview-0514  
> - gemini-2.0-flash-001  
> - gemini-2.0-flash-exp  
> - gemini-2.0-flash-thinking-exp  
> - gemini-2.0-flash-thinking-exp-01-21  
> - gemini-2.0-pro-exp-02-05  
> - gemini-flash-experimental  
> - gemini-pro  
> - gemini-pro-experimental  
> - gemini-pro-vision  
> - gemini/gemini-1.5-flash  
> - gemini/gemini-1.5-flash-001  
> - gemini/gemini-1.5-flash-002  
> - gemini/gemini-1.5-flash-8b  
> - gemini/gemini-1.5-flash-8b-exp-0827  
> - gemini/gemini-1.5-flash-8b-exp-0924  
> - gemini/gemini-1.5-flash-exp-0827  
> - gemini/gemini-1.5-flash-latest  
> - gemini/gemini-1.5-pro  
> - gemini/gemini-1.5-pro-001  
> - gemini/gemini-1.5-pro-002  
> - gemini/gemini-1.5-pro-exp-0801  
> - gemini/gemini-1.5-pro-exp-0827  
> - gemini/gemini-1.5-pro-latest  
> - gemini/gemini-2.0-flash  
> - gemini/gemini-2.0-flash-001  
> - gemini/gemini-2.0-flash-exp  
> - gemini/gemini-2.0-flash-lite-preview-02-05  
> - gemini/gemini-2.0-flash-thinking-exp  
> - gemini/gemini-exp-1114  
> - gemini/gemini-exp-1206  
> - gemini/gemini-gemma-2-27b-it  
> - gemini/gemini-gemma-2-9b-it  
> - gemini/gemini-pro  
> - gemini/gemini-pro-vision  
> - gpt-3.5-turbo  
> - gpt-3.5-turbo-0125  
> - gpt-3.5-turbo-0301  
> - gpt-3.5-turbo-0613  
> - gpt-3.5-turbo-1106  
> - gpt-3.5-turbo-16k  
> - gpt-3.5-turbo-16k-0613  
> - gpt-4  
> - gpt-4-0125-preview  
> - gpt-4-0314  
> - gpt-4-0613  
> - gpt-4-1106-preview  
> - gpt-4-1106-vision-preview  
> - gpt-4-32k  
> - gpt-4-32k-0314  
> - gpt-4-32k-0613  
> - gpt-4-turbo  
> - gpt-4-turbo-2024-04-09  
> - gpt-4-turbo-preview  
> - gpt-4-vision-preview  
> - gpt-4o  
> - gpt-4o-2024-05-13  
> - gpt-4o-2024-08-06  
> - gpt-4o-2024-11-20  
> - gpt-4o-audio-preview  
> - gpt-4o-audio-preview-2024-10-01  
> - gpt-4o-audio-preview-2024-12-17  
> - gpt-4o-mini  
> - gpt-4o-mini-2024-07-18  
> - gpt-4o-mini-audio-preview-2024-12-17  
> - gpt-4o-mini-realtime-preview  
> - gpt-4o-mini-realtime-preview-2024-12-17  
> - gpt-4o-realtime-preview  
> - gpt-4o-realtime-preview-2024-10-01  
> - gpt-4o-realtime-preview-2024-12-17  
> - groq/deepseek-r1-distill-llama-70b  
> - groq/gemma-7b-it  
> - groq/gemma2-9b-it  
> - groq/llama-3.1-405b-reasoning  
> - groq/llama-3.1-70b-versatile  
> - groq/llama-3.1-8b-instant  
> - groq/llama-3.2-11b-text-preview  
> - groq/llama-3.2-11b-vision-preview  
> - groq/llama-3.2-1b-preview  
> - groq/llama-3.2-3b-preview  
> - groq/llama-3.2-90b-text-preview  
> - groq/llama-3.2-90b-vision-preview  
> - groq/llama-3.3-70b-specdec  
> - groq/llama-3.3-70b-versatile  
> - groq/llama2-70b-4096  
> - groq/llama3-70b-8192  
> - groq/llama3-8b-8192  
> - groq/llama3-groq-70b-8192-tool-use-preview  
> - groq/llama3-groq-8b-8192-tool-use-preview  
> - groq/mixtral-8x7b-32768  
> - jamba-1.5  
> - jamba-1.5-large  
> - jamba-1.5-large@001  
> - jamba-1.5-mini  
> - jamba-1.5-mini@001  
> - luminous-base-control  
> - luminous-extended-control  
> - luminous-supreme-control  
> - medlm-large  
> - medlm-medium  
> - meta.llama2-13b-chat-v1  
> - meta.llama2-70b-chat-v1  
> - meta.llama3-1-405b-instruct-v1:0  
> - meta.llama3-1-70b-instruct-v1:0  
> - meta.llama3-1-8b-instruct-v1:0  
> - meta.llama3-2-11b-instruct-v1:0  
> - meta.llama3-2-1b-instruct-v1:0  
> - meta.llama3-2-3b-instruct-v1:0  
> - meta.llama3-2-90b-instruct-v1:0  
> - meta.llama3-3-70b-instruct-v1:0  
> - meta.llama3-70b-instruct-v1:0  
> - meta.llama3-8b-instruct-v1:0  
> - mistral.mistral-7b-instruct-v0:2  
> - mistral.mistral-large-2402-v1:0  
> - mistral.mistral-large-2407-v1:0  
> - mistral.mistral-small-2402-v1:0  
> - mistral.mixtral-8x7b-instruct-v0:1  
> - mistral/codestral-2405  
> - mistral/codestral-latest  
> - mistral/codestral-mamba-latest  
> - mistral/mistral-large-2402  
> - mistral/mistral-large-2407  
> - mistral/mistral-large-2411  
> - mistral/mistral-large-latest  
> - mistral/mistral-medium  
> - mistral/mistral-medium-2312  
> - mistral/mistral-medium-latest  
> - mistral/mistral-small  
> - mistral/mistral-small-latest  
> - mistral/mistral-tiny  
> - mistral/open-codestral-mamba  
> - mistral/open-mistral-7b  
> - mistral/open-mistral-nemo  
> - mistral/open-mistral-nemo-2407  
> - mistral/open-mixtral-8x22b  
> - mistral/open-mixtral-8x7b  
> - mistral/pixtral-12b-2409  
> - mistral/pixtral-large-2411  
> - mistral/pixtral-large-latest  
> - nlp_cloud/chatdolphin  
> - o1  
> - o1-2024-12-17  
> - o1-mini  
> - o1-mini-2024-09-12  
> - o1-preview  
> - o1-preview-2024-09-12  
> - o3-mini  
> - o3-mini-2025-01-31  
> - ollama/codegeex4  
> - ollama/deepseek-coder-v2-instruct  
> - ollama/deepseek-coder-v2-lite-instruct  
> - ollama/internlm2_5-20b-chat  
> - ollama/llama2  
> - ollama/llama2:13b  
> - ollama/llama2:70b  
> - ollama/llama2:7b  
> - ollama/llama3  
> - ollama/llama3.1  
> - ollama/llama3:70b  
> - ollama/llama3:8b  
> - ollama/mistral-7B-Instruct-v0.1  
> - ollama/mistral-7B-Instruct-v0.2  
> - ollama/mistral-large-instruct-2407  
> - ollama/mixtral-8x22B-Instruct-v0.1  
> - ollama/mixtral-8x7B-Instruct-v0.1  
> - openai/chatgpt-4o-latest  
> - openai/ft:gpt-3.5-turbo  
> - openai/ft:gpt-3.5-turbo-0125  
> - openai/ft:gpt-3.5-turbo-0613  
> - openai/ft:gpt-3.5-turbo-1106  
> - openai/ft:gpt-4-0613  
> - openai/ft:gpt-4o-2024-08-06  
> - openai/ft:gpt-4o-2024-11-20  
> - openai/ft:gpt-4o-mini-2024-07-18  
> - openai/gpt-3.5-turbo  
> - openai/gpt-3.5-turbo-0125  
> - openai/gpt-3.5-turbo-0301  
> - openai/gpt-3.5-turbo-0613  
> - openai/gpt-3.5-turbo-1106  
> - openai/gpt-3.5-turbo-16k  
> - openai/gpt-3.5-turbo-16k-0613  
> - openai/gpt-4  
> - openai/gpt-4-0125-preview  
> - openai/gpt-4-0314  
> - openai/gpt-4-0613  
> - openai/gpt-4-1106-preview  
> - openai/gpt-4-1106-vision-preview  
> - openai/gpt-4-32k  
> - openai/gpt-4-32k-0314  
> - openai/gpt-4-32k-0613  
> - openai/gpt-4-turbo  
> - openai/gpt-4-turbo-2024-04-09  
> - openai/gpt-4-turbo-preview  
> - openai/gpt-4-vision-preview  
> - openai/gpt-4o  
> - openai/gpt-4o-2024-05-13  
> - openai/gpt-4o-2024-08-06  
> - openai/gpt-4o-2024-11-20  
> - openai/gpt-4o-audio-preview  
> - openai/gpt-4o-audio-preview-2024-10-01  
> - openai/gpt-4o-audio-preview-2024-12-17  
> - openai/gpt-4o-mini  
> - openai/gpt-4o-mini-2024-07-18  
> - openai/gpt-4o-mini-audio-preview-2024-12-17  
> - openai/gpt-4o-mini-realtime-preview  
> - openai/gpt-4o-mini-realtime-preview-2024-12-17  
> - openai/gpt-4o-realtime-preview  
> - openai/gpt-4o-realtime-preview-2024-10-01  
> - openai/gpt-4o-realtime-preview-2024-12-17  
> - openai/o1  
> - openai/o1-2024-12-17  
> - openai/o1-mini  
> - openai/o1-mini-2024-09-12  
> - openai/o1-preview  
> - openai/o1-preview-2024-09-12  
> - openai/o3-mini  
> - openai/o3-mini-2025-01-31  
> - openrouter/anthropic/claude-2  
> - openrouter/anthropic/claude-3-5-haiku  
> - openrouter/anthropic/claude-3-5-haiku-20241022  
> - openrouter/anthropic/claude-3-haiku  
> - openrouter/anthropic/claude-3-haiku-20240307  
> - openrouter/anthropic/claude-3-opus  
> - openrouter/anthropic/claude-3-sonnet  
> - openrouter/anthropic/claude-3.5-sonnet  
> - openrouter/anthropic/claude-3.5-sonnet:beta  
> - openrouter/anthropic/claude-instant-v1  
> - openrouter/cognitivecomputations/dolphin-mixtral-8x7b  
> - openrouter/cohere/command-r-plus  
> - openrouter/databricks/dbrx-instruct  
> - openrouter/deepseek/deepseek-chat  
> - openrouter/deepseek/deepseek-coder  
> - openrouter/deepseek/deepseek-r1  
> - openrouter/fireworks/firellava-13b  
> - openrouter/google/gemini-2.0-flash-001  
> - openrouter/google/gemini-pro-1.5  
> - openrouter/google/gemini-pro-vision  
> - openrouter/google/palm-2-chat-bison  
> - openrouter/google/palm-2-codechat-bison  
> - openrouter/gryphe/mythomax-l2-13b  
> - openrouter/jondurbin/airoboros-l2-70b-2.1  
> - openrouter/mancer/weaver  
> - openrouter/meta-llama/codellama-34b-instruct  
> - openrouter/meta-llama/llama-2-13b-chat  
> - openrouter/meta-llama/llama-2-70b-chat  
> - openrouter/meta-llama/llama-3-70b-instruct  
> - openrouter/meta-llama/llama-3-70b-instruct:nitro  
> - openrouter/meta-llama/llama-3-8b-instruct:extended  
> - openrouter/meta-llama/llama-3-8b-instruct:free  
> - openrouter/microsoft/wizardlm-2-8x22b:nitro  
> - openrouter/mistralai/mistral-7b-instruct  
> - openrouter/mistralai/mistral-7b-instruct:free  
> - openrouter/mistralai/mistral-large  
> - openrouter/mistralai/mixtral-8x22b-instruct  
> - openrouter/nousresearch/nous-hermes-llama2-13b  
> - openrouter/openai/gpt-3.5-turbo  
> - openrouter/openai/gpt-3.5-turbo-16k  
> - openrouter/openai/gpt-4  
> - openrouter/openai/gpt-4-vision-preview  
> - openrouter/openai/gpt-4o  
> - openrouter/openai/gpt-4o-2024-05-13  
> - openrouter/openai/o1  
> - openrouter/openai/o1-mini  
> - openrouter/openai/o1-mini-2024-09-12  
> - openrouter/openai/o1-preview  
> - openrouter/openai/o1-preview-2024-09-12  
> - openrouter/pygmalionai/mythalion-13b  
> - openrouter/qwen/qwen-2.5-coder-32b-instruct  
> - openrouter/undi95/remm-slerp-l2-13b  
> - palm/chat-bison  
> - palm/chat-bison-001  
> - perplexity/codellama-34b-instruct  
> - perplexity/codellama-70b-instruct  
> - perplexity/llama-2-70b-chat  
> - perplexity/llama-3.1-70b-instruct  
> - perplexity/llama-3.1-8b-instruct  
> - perplexity/llama-3.1-sonar-huge-128k-online  
> - perplexity/llama-3.1-sonar-large-128k-chat  
> - perplexity/llama-3.1-sonar-large-128k-online  
> - perplexity/llama-3.1-sonar-small-128k-chat  
> - perplexity/llama-3.1-sonar-small-128k-online  
> - perplexity/mistral-7b-instruct  
> - perplexity/mixtral-8x7b-instruct  
> - perplexity/pplx-70b-chat  
> - perplexity/pplx-70b-online  
> - perplexity/pplx-7b-chat  
> - perplexity/pplx-7b-online  
> - perplexity/sonar  
> - perplexity/sonar-medium-chat  
> - perplexity/sonar-medium-online  
> - perplexity/sonar-pro  
> - perplexity/sonar-small-chat  
> - perplexity/sonar-small-online  
> - replicate/meta/llama-2-13b  
> - replicate/meta/llama-2-13b-chat  
> - replicate/meta/llama-2-70b  
> - replicate/meta/llama-2-70b-chat  
> - replicate/meta/llama-2-7b  
> - replicate/meta/llama-2-7b-chat  
> - replicate/meta/llama-3-70b  
> - replicate/meta/llama-3-70b-instruct  
> - replicate/meta/llama-3-8b  
> - replicate/meta/llama-3-8b-instruct  
> - replicate/mistralai/mistral-7b-instruct-v0.2  
> - replicate/mistralai/mistral-7b-v0.1  
> - replicate/mistralai/mixtral-8x7b-instruct-v0.1  
> - sagemaker/meta-textgeneration-llama-2-13b-f  
> - sagemaker/meta-textgeneration-llama-2-70b-b-f  
> - sagemaker/meta-textgeneration-llama-2-7b-f  
> - sambanova/Meta-Llama-3.1-405B-Instruct  
> - sambanova/Meta-Llama-3.1-70B-Instruct  
> - sambanova/Meta-Llama-3.1-8B-Instruct  
> - sambanova/Meta-Llama-3.2-1B-Instruct  
> - sambanova/Meta-Llama-3.2-3B-Instruct  
> - sambanova/Qwen2.5-72B-Instruct  
> - sambanova/Qwen2.5-Coder-32B-Instruct  
> - together-ai-21.1b-41b  
> - together-ai-4.1b-8b  
> - together-ai-41.1b-80b  
> - together-ai-8.1b-21b  
> - together-ai-81.1b-110b  
> - together-ai-up-to-4b  
> - together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo  
> - together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free  
> - together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo  
> - together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo  
> - together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo  
> - together_ai/mistralai/Mistral-7B-Instruct-v0.1  
> - together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1  
> - together_ai/together-ai-21.1b-41b  
> - together_ai/together-ai-4.1b-8b  
> - together_ai/together-ai-41.1b-80b  
> - together_ai/together-ai-8.1b-21b  
> - together_ai/together-ai-81.1b-110b  
> - together_ai/together-ai-up-to-4b  
> - together_ai/togethercomputer/CodeLlama-34b-Instruct  
> - us.amazon.nova-lite-v1:0  
> - us.amazon.nova-micro-v1:0  
> - us.amazon.nova-pro-v1:0  
> - us.anthropic.claude-3-5-haiku-20241022-v1:0  
> - us.anthropic.claude-3-5-sonnet-20240620-v1:0  
> - us.anthropic.claude-3-5-sonnet-20241022-v2:0  
> - us.anthropic.claude-3-haiku-20240307-v1:0  
> - us.anthropic.claude-3-opus-20240229-v1:0  
> - us.anthropic.claude-3-sonnet-20240229-v1:0  
> - us.meta.llama3-1-405b-instruct-v1:0  
> - us.meta.llama3-1-70b-instruct-v1:0  
> - us.meta.llama3-1-8b-instruct-v1:0  
> - us.meta.llama3-2-11b-instruct-v1:0  
> - us.meta.llama3-2-1b-instruct-v1:0  
> - us.meta.llama3-2-3b-instruct-v1:0  
> - us.meta.llama3-2-90b-instruct-v1:0  
> - us.meta.llama3-3-70b-instruct-v1:0  
> - vertex_ai-ai21_models/vertex_ai/jamba-1.5  
> - vertex_ai-ai21_models/vertex_ai/jamba-1.5-large  
> - vertex_ai-ai21_models/vertex_ai/jamba-1.5-large@001  
> - vertex_ai-ai21_models/vertex_ai/jamba-1.5-mini  
> - vertex_ai-ai21_models/vertex_ai/jamba-1.5-mini@001  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-haiku  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-haiku@20241022  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet-v2  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet-v2@20241022  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet@20240620  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-7-sonnet-20250219  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-haiku  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-haiku@20240307  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-opus  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-opus@20240229  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-sonnet  
> - vertex_ai-anthropic_models/vertex_ai/claude-3-sonnet@20240229  
> - vertex_ai-chat-models/chat-bison  
> - vertex_ai-chat-models/chat-bison-32k  
> - vertex_ai-chat-models/chat-bison-32k@002  
> - vertex_ai-chat-models/chat-bison@001  
> - vertex_ai-chat-models/chat-bison@002  
> - vertex_ai-code-chat-models/codechat-bison  
> - vertex_ai-code-chat-models/codechat-bison-32k  
> - vertex_ai-code-chat-models/codechat-bison-32k@002  
> - vertex_ai-code-chat-models/codechat-bison@001  
> - vertex_ai-code-chat-models/codechat-bison@002  
> - vertex_ai-code-chat-models/codechat-bison@latest  
> - vertex_ai-code-text-models/code-bison  
> - vertex_ai-language-models/gemini-1.0-pro  
> - vertex_ai-language-models/gemini-1.0-pro-001  
> - vertex_ai-language-models/gemini-1.0-pro-002  
> - vertex_ai-language-models/gemini-1.0-ultra  
> - vertex_ai-language-models/gemini-1.0-ultra-001  
> - vertex_ai-language-models/gemini-1.5-flash  
> - vertex_ai-language-models/gemini-1.5-flash-001  
> - vertex_ai-language-models/gemini-1.5-flash-002  
> - vertex_ai-language-models/gemini-1.5-flash-exp-0827  
> - vertex_ai-language-models/gemini-1.5-flash-preview-0514  
> - vertex_ai-language-models/gemini-1.5-pro  
> - vertex_ai-language-models/gemini-1.5-pro-001  
> - vertex_ai-language-models/gemini-1.5-pro-002  
> - vertex_ai-language-models/gemini-1.5-pro-preview-0215  
> - vertex_ai-language-models/gemini-1.5-pro-preview-0409  
> - vertex_ai-language-models/gemini-1.5-pro-preview-0514  
> - vertex_ai-language-models/gemini-2.0-flash-001  
> - vertex_ai-language-models/gemini-2.0-flash-exp  
> - vertex_ai-language-models/gemini-2.0-flash-thinking-exp  
> - vertex_ai-language-models/gemini-2.0-flash-thinking-exp-01-21  
> - vertex_ai-language-models/gemini-2.0-pro-exp-02-05  
> - vertex_ai-language-models/gemini-flash-experimental  
> - vertex_ai-language-models/gemini-pro  
> - vertex_ai-language-models/gemini-pro-experimental  
> - vertex_ai-language-models/medlm-large  
> - vertex_ai-language-models/medlm-medium  
> - vertex_ai-llama_models/vertex_ai/meta/llama-3.2-90b-vision-instruct-maas  
> - vertex_ai-llama_models/vertex_ai/meta/llama3-405b-instruct-maas  
> - vertex_ai-llama_models/vertex_ai/meta/llama3-70b-instruct-maas  
> - vertex_ai-llama_models/vertex_ai/meta/llama3-8b-instruct-maas  
> - vertex_ai-mistral_models/vertex_ai/codestral-2501  
> - vertex_ai-mistral_models/vertex_ai/codestral@2405  
> - vertex_ai-mistral_models/vertex_ai/codestral@latest  
> - vertex_ai-mistral_models/vertex_ai/mistral-large-2411  
> - vertex_ai-mistral_models/vertex_ai/mistral-large@2407  
> - vertex_ai-mistral_models/vertex_ai/mistral-large@2411-001  
> - vertex_ai-mistral_models/vertex_ai/mistral-large@latest  
> - vertex_ai-mistral_models/vertex_ai/mistral-nemo@2407  
> - vertex_ai-mistral_models/vertex_ai/mistral-nemo@latest  
> - vertex_ai-vision-models/gemini-1.0-pro-vision  
> - vertex_ai-vision-models/gemini-1.0-pro-vision-001  
> - vertex_ai-vision-models/gemini-pro-vision  
> - vertex_ai/claude-3-5-haiku  
> - vertex_ai/claude-3-5-haiku@20241022  
> - vertex_ai/claude-3-5-sonnet  
> - vertex_ai/claude-3-5-sonnet-v2  
> - vertex_ai/claude-3-5-sonnet-v2@20241022  
> - vertex_ai/claude-3-5-sonnet@20240620  
> - vertex_ai/claude-3-7-sonnet-20250219  
> - vertex_ai/claude-3-haiku  
> - vertex_ai/claude-3-haiku@20240307  
> - vertex_ai/claude-3-opus  
> - vertex_ai/claude-3-opus@20240229  
> - vertex_ai/claude-3-sonnet  
> - vertex_ai/claude-3-sonnet@20240229  
> - vertex_ai/codestral-2501  
> - vertex_ai/codestral@2405  
> - vertex_ai/codestral@latest  
> - vertex_ai/jamba-1.5  
> - vertex_ai/jamba-1.5-large  
> - vertex_ai/jamba-1.5-large@001  
> - vertex_ai/jamba-1.5-mini  
> - vertex_ai/jamba-1.5-mini@001  
> - vertex_ai/meta/llama-3.2-90b-vision-instruct-maas  
> - vertex_ai/meta/llama3-405b-instruct-maas  
> - vertex_ai/meta/llama3-70b-instruct-maas  
> - vertex_ai/meta/llama3-8b-instruct-maas  
> - vertex_ai/mistral-large-2411  
> - vertex_ai/mistral-large@2407  
> - vertex_ai/mistral-large@2411-001  
> - vertex_ai/mistral-large@latest  
> - vertex_ai/mistral-nemo@2407  
> - vertex_ai/mistral-nemo@latest  
> - xai/grok-2  
> - xai/grok-2-1212  
> - xai/grok-2-latest  
> - xai/grok-2-vision  
> - xai/grok-2-vision-1212  
> - xai/grok-2-vision-latest  
> - xai/grok-beta  
> - xai/grok-vision-beta  
> Warning: gpt-4-turbo-preview expects these environment variables  
> - OPENAI_API_KEY: Not set  
> Note: You may need to restart your terminal or command prompt for `setx` to take effect.  
> Aider v0.74.3  
> Main model:  with udiff edit format  
> Weak model: gpt-4-turbo-preview  
> Git repo: ..\.git with 573 files  
> Repo-map: using 4096 tokens, auto refresh  
> Warning: map-tokens > 2048 is not recommended. Too much irrelevant code can confuse LLMs.  

#### can you review the settings?  
> litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=  
> Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers  
> https://docs.litellm.ai/docs/providers  
>  
>  
> ^C again to exit  

#### /exit  
