2024-11-28 17:36:35,484 - INFO - Logging initialized.
2024-11-28 17:36:35,484 - INFO - Step: Starting tokenization process
2024-11-28 17:36:35,486 - INFO - Step: Reading file: c:/school_board_library/experiments/2_modularization_Ollama/inbound_documents/8-27-2024.auto_generated_captions_converted.txt
2024-11-28 17:36:35,491 - INFO - Step: File read successfully.
2024-11-28 17:36:35,491 - INFO - Step: Tokenizing content...
2024-11-28 17:36:37,728 - INFO - Step: Tokenization completed.
2024-11-28 17:36:37,729 - INFO - Step: Saving token summary to file: c:/school_board_library/experiments/2_modularization_Ollama/outbound_documents/tokenized_output.txt
2024-11-28 17:36:37,754 - INFO - Step: Token summary saved successfully.
2024-11-28 17:36:37,758 - INFO - Step: Saving token summary to file: C:\school_board_library\experiments\2_modularization_Ollama\data\model_output\tokens_8-27-2024.auto_generated_captions_converted_20241128173637.txt
2024-11-28 17:36:37,765 - INFO - Step: Token summary saved successfully.
2024-11-28 17:36:37,765 - INFO - Step: Token summary saved to model_output file: C:\school_board_library\experiments\2_modularization_Ollama\data\model_output\tokens_8-27-2024.auto_generated_captions_converted_20241128173637.txt
2024-11-28 17:36:37,765 - INFO - Step: Tokenization process completed in 2.2810 seconds
2024-11-28 17:36:37,767 - INFO - Number of tokens: 95402
